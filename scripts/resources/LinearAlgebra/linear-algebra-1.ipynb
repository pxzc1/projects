{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4deee0b3",
   "metadata": {},
   "source": [
    "### This Linear Algebra Course is provided by Jon Kronh [`(youtube.com)`](https://youtube.com/playlist?list=PLRDl2inPrWQW1QSWhBU0ki-jq_uElkh2a&si=enoqESi8RweoMRqV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bafab63",
   "metadata": {},
   "source": [
    "## 1 Tensors\n",
    "**Description:** Machine Learning (ML) generalization of vectors and matrics to any number of dimensions. (สามารถสรุปผลเวกเตอร์และเมทริกซ์ไปยังมิติใดๆก็ได้)\n",
    "\n",
    "| Dimensions | Mathematical Name | Description                         |\n",
    "|------------|-------------------|-------------------------------------|\n",
    "| $0$        | Scalar            | Magnitude only, มีเพียงขนาด (ไม่มีทิศทาง)                    |\n",
    "| $1$        | Vector            | Array                               |\n",
    "| $2$        | Matrix            | Flat table (e.g., square)           |\n",
    "| $3$        | $3$-tensor        | 3D table (e.g., cube)               |\n",
    "| $n$        | $n$-tensor        | Higher-dimensional |\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31006056",
   "metadata": {},
   "source": [
    "## 1.1 Scalars\n",
    "- No dimension\n",
    "- Single number\n",
    "- Denoted in lowercase, italics, e.g.: $\\mathbf{x}$, ${x}$\n",
    "- Should be typed, like all other tensors: e.g., int (integer), float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd0f9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'int'>\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "x_scalar = 25\n",
    "print(type(x_scalar))\n",
    "\n",
    "y_scalar = 3\n",
    "print(type(y_scalar))\n",
    "\n",
    "print(x_scalar+y_scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f508d",
   "metadata": {},
   "source": [
    "## 1.1.1 Scalars in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cccf54a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_torch_scalar = torch.tensor(25)\n",
    "print(type(x_torch_scalar))\n",
    "print(x_torch_scalar.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cec78d3",
   "metadata": {},
   "source": [
    "- **PyTorch are designed to be pythonic**, so it's easier to use and learn. TensorFlow is for infrastructure.\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75a8c98",
   "metadata": {},
   "source": [
    "## 1.2 Vectors\n",
    "- One-dimension array of numbers\n",
    "- Denoted in lowercase, italics, bold, e.g., $\\mathbf{x}$, ${x}$, *x*\n",
    "- Arranged in an order, element can be accessed by its index `(idx)`\n",
    "    - Elements are scalar (not bold), e.g., second element of $\\mathbf{x}$ is ${x}_2$\n",
    "- Representing a point in space: $[x_1,  \\space x_2] = [12, \\space 4]$\n",
    "    - Vector of length: two, represents location in 2D matrix\n",
    "    - Vector of length: three, represents location in 3D cube\n",
    "    - Vector of n length, represents location in n-dimensional tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7075a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "<class 'numpy.ndarray'> 3 (3,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_vector = np.array([1,2,3]) #column\n",
    "print(x_vector)\n",
    "print(type(x_vector), len(x_vector), x_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf624aee",
   "metadata": {},
   "source": [
    "`.shape` is an attribute to check for `np.array()` shape (or dimension)\n",
    "and we could indexed it by using: e.g., `x_vector[0]` (as python start its index at 0), this will return 1 (int). \n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64f198b",
   "metadata": {},
   "source": [
    "## 1.2.1 Vector Transpoition\n",
    "- Example: \n",
    "\n",
    "$$[x_{1}, \\space x_{2}, \\space x_{3}]\\top =\n",
    "\\begin{bmatrix}\n",
    "x_{1} \\\\\\\\\n",
    "x_{2} \\\\\\\\\n",
    "x_{3}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- Tranpsotion is denoted as $-\\top$\n",
    "- Transpose row vector $\\to$ column vector, or column vector $\\to$ row vector. (shape $(3,1)$ $\\to$ shape $(1,3)$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5323590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] (3,)\n",
      "(4,) [1 2 3 4] (4,)\n",
      "[[1 4 7]\n",
      " [2 5 8]\n",
      " [3 6 9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(x_vector.T, x_vector.T.shape)\n",
    "\n",
    "y_vector = np.array([1,2,3,4]) #column\n",
    "print(y_vector.shape, y_vector.T, y_vector.T.shape)\n",
    "\n",
    "z_vector = np.array([[1,2,3], [4,5,6], [7,8,9]]) #rows and columns\n",
    "print(z_vector.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403f9440",
   "metadata": {},
   "source": [
    "`np.array()` for higher dimensions, it will needs more `[]`. so it defines both row, column.\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fa582c",
   "metadata": {},
   "source": [
    "## 1.2.2 Zero Vectors\n",
    "- Have no effects if added to another vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "746e12c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.zeros(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d4e293",
   "metadata": {},
   "source": [
    "Zero Vector can be defined using: `np.zeros(<value>)`\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2506a4",
   "metadata": {},
   "source": [
    "## 1.2.3 Vectors in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43bc40e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3]) 3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_vector = torch.tensor([[1,2,3], [4,5,6], [7,8,9]])\n",
    "print(x_vector.shape, len(x_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088b1670",
   "metadata": {},
   "source": [
    "Torch use `torch.tensor()` to define array, similarly to NumPy.\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd6ed1b",
   "metadata": {},
   "source": [
    "## 1.3 Norms\n",
    "- Vector represent a magnitude (ขนาด) and direction from origin\n",
    "\n",
    "- **Norm are function that quantify vector magnitude** (ฟังก์ชันที่ใช้วัดขนาดของเวกเตอร์)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ff469",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8dce05",
   "metadata": {},
   "source": [
    "## 1.3.1 $L^{2}$ Norm (Euclidean Norm)\n",
    "- Described by:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\|x\\|_2 = \\sqrt{\\sum_{i=1}^{n} x_i^2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "(**How it works**: square root of sum of all element that squared by 2)\n",
    "- Measures simple (Euclidean) distance from origin\n",
    "- Most common norm in Machine Learning\n",
    "    - Insteaad of $\\|x\\|_2$, it can be denoted as $\\|x\\|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5dc2dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7416573867739413\n",
      "Iterates: 3.7416573867739413\n",
      "LA: 3.7416573867739413\n",
      "np.linalg.norm: 3.7416573867739413\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_l2 = np.array([1,2,3])\n",
    "print(((1**2) + (2**2) + (3**2))**(1/2))\n",
    "\n",
    "#iterates through each element to computes euclidean norm.\n",
    "summ = 0\n",
    "for _ in range(len(x_l2)):\n",
    "    summ += (x_l2[_]**2)\n",
    "\n",
    "print(f'Iterates: {summ**(1/2)}')\n",
    "\n",
    "#or use np.linalg.norm()\n",
    "from numpy import linalg as LA\n",
    "print(f'LA: {LA.norm(x_l2)}')\n",
    "print(f'np.linalg.norm: {np.linalg.norm(x_l2)}') #this function will default to euclidean norm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097d40e4",
   "metadata": {},
   "source": [
    "So this mean, vector `x_l2` has a length of $25.6$ meters.\n",
    "\n",
    "As you can see: we could use many different ways to compute $L^2$ Norm:\n",
    "- `np.linalg.norm()`  This is the easist way as this function default to $L^2$ Norm.\n",
    "- Or simply use `from numpy import linalg as LA` (LA is common alias) and then `LA.norm()`.\n",
    "- Or if you understand it just iterates through each element or if you know what element is inside just square each element by 2 and then sum it and square root.\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07312641",
   "metadata": {},
   "source": [
    "## 1.3.2 Unit Vector\n",
    "- Special case of vector where its length is equal to $1$.\n",
    "    - if $\\|x\\| = 1$, $x$ is unit vector.\n",
    "- Technically, $x$ is a unit vector with \"unit norm\", i.e., $\\|x\\| = 1$\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7e5a06",
   "metadata": {},
   "source": [
    "## 1.3.3 $L^1$ Norm\n",
    "- Described by:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\|x\\|_1 = \\sum_{i=1}^{n} |x_i|\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "- Another common norm in Machine Learning\n",
    "- Varies linearly at all locations whether near or far from origin\n",
    "- Used whenever difference between zero and non-zero is key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e2c7d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Iterates: 6\n",
      "LA: 6.0\n",
      "np.linalg.norm: 6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_l1 = np.array([1,2,3])\n",
    "print(np.abs(1) + np.abs(2) + np.abs(3)) #basic\n",
    "\n",
    "#or iterate through each element.\n",
    "summ = 0\n",
    "for _ in range(len(x_l1)):\n",
    "    summ += (np.abs(x_l1[_]))\n",
    "    \n",
    "print(f'Iterates: {summ}')\n",
    "\n",
    "#or using np.linalg.norm(, ord=1)\n",
    "from numpy import linalg as LA\n",
    "print(f'LA: {LA.norm(x_l2, ord=1)}')\n",
    "print(f'np.linalg.norm: {np.linalg.norm(x_l2, ord=1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c97fad",
   "metadata": {},
   "source": [
    "So the $L^1$ norm result of this vector is $6$.\n",
    "\n",
    "We can use `np.linalg.norm(, ord=1)` to specify which order of norm function will be use to compute. in this case it's $1$ for $L^1$ norm.\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77883ac3",
   "metadata": {},
   "source": [
    "## 1.3.4 Squared $L^2$ Norm\n",
    "- Basically sum of all element squared by $2$ (without square root because this is squared $L^2$ norm).\n",
    "- Described by:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\|x\\|_2^2 = \\sum_{i=1}^{n} x_i^2\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "- Computationally cheaper to compute than $L^2$ norm because:\n",
    "    - Squared $L^2$ Norm equals simply $x^\\top{x}$ ($x$ tranposed multiplied with vector $x$)\n",
    "    - Derivative (used to train many Machine Learning algorithms) of element $x$ , requires that element alone, whereas $L^2$ norm requires $x$ vector.\n",
    "    อนุพันธ์ คำนวณจาก องค์ประกอบเดี่ยว $x$ เพียงตัวเดียวในขณะที่ ค่า $L^2$ Norm จำเป็นต้องใช้ เวกเตอร์ $x$ ทั้งชุด\n",
    "- Downside is it grows slowly near origin, so can't be used if distinguishing between zero and near-zero is important.\n",
    "\n",
    "ข้อเสียคือ ค่าจะเพิ่มขึ้นช้ามากใกล้จุดกำเนิด (origin) ดังนั้น ไม่เหมาะสำหรับกรณีที่ต้องแยกความแตกต่างระหว่างค่าเป็นศูนย์กับค่าใกล้ศูนย์อย่างชัดเจน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75bd0aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic: 14\n",
      "Iterates: 14\n",
      "LA: 14.0\n",
      "np.linalg.norm: 14.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_sl2 = np.array([1,2,3])\n",
    "print(f'Basic: {1**2 + 2**2 + 3**2}')\n",
    "\n",
    "#iteration\n",
    "summ = 0\n",
    "for _ in range(len(x_sl2)):\n",
    "    summ += (x_sl2[_]**2)\n",
    "    \n",
    "print(f'Iterates: {summ}')\n",
    "\n",
    "#using LA or linalg.norm()\n",
    "from numpy import linalg as LA\n",
    "print(f'LA: {(LA.norm(x_sl2))**2}')\n",
    "print(f'np.linalg.norm: {(np.linalg.norm(x_sl2))**2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde61c9d",
   "metadata": {},
   "source": [
    "It's just $L^2$ norm with no square root, but with `np.linalg.norm(x)` we just need to square it up.\n",
    "Or we can just use `np.dot()` to calculate this Squared $L^2$ Norm.\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ea1b60",
   "metadata": {},
   "source": [
    "## 1.3.5 Max Norm ($L^{\\infty}$ Norm/Supremum Norm)\n",
    "- Described by:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\|x\\|_{\\infty} = \\max_{i=1,\\dots,n} |x_i|\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "- Also appear frequently in Machine Learning\n",
    "- Returns the absolute value of the largest-magnitude element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df1bc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic: 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_max = np.array([1,2,3])\n",
    "print(f'Basic: {np.max([np.abs(1), np.abs(2), np.abs(3)])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597be22",
   "metadata": {},
   "source": [
    "It's basically maximum value of absoluted element in a vector.\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42a006a",
   "metadata": {},
   "source": [
    "## 1.3.6 Generalized $L^{p}$ Norm\n",
    "- Described by:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\|x\\|_p = \\left( \\sum_{i=1}^{n} |x_i|^p \\right)^{\\frac{1}{p}}, \\quad p \\ge 1\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "- If we want to calculate $L^2$ Norm, we can just enter `p = 2`:\n",
    "    - $p$ must be real number.\n",
    "    - Greater than or equal to $1$\n",
    "- Can derive $L^1$, $L^2$, and $L^{\\infty}$ norm formulae by substituting (แทนที่) $p$.\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac354a8e",
   "metadata": {},
   "source": [
    "## 1.3.7 Basis Vectors\n",
    "- Can be scaled to represent any vector in a given vector space\n",
    "- Typically use unit vector along axes of vector space\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c617c7",
   "metadata": {},
   "source": [
    "## 1.3.8 Orthogonal Vectors\n",
    "- $x$ and $y$ are orthogonal vector if $x^\\top y = 0$\n",
    "- Are at $\\deg{90}$ angle to each other (assuming non-zero norms)\n",
    "- n-dimensional space has max $n$ mutually orthogonal vector\n",
    "    - Example: if it's 3 dimensional space then mostly it has maximum 3 mutually orthogonal vectors.\n",
    "- **Orthogonal** vectors are orthogonal and all have unit norm\n",
    "    - Basis vectors are an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a00d1bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "i_ortho = np.array([1,0])\n",
    "j_ortho = np.array([0,1])\n",
    "print(np.dot(i_ortho,j_ortho))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0482c065",
   "metadata": {},
   "source": [
    "After `np.dot(i_ortho, j_ortho)`, it clearly showing that the result of dot product is 0, which relate to that $x$, $y$ are orthogonal if $x^\\top y = 0$\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6451bb5",
   "metadata": {},
   "source": [
    "## 1.4 Matrics\n",
    "- 2-dimensional array of numbers\n",
    "- Denoted in uppercase, italics, bold\n",
    "- height given priority ahead of width in notation, i.e., $(\\text{n}_\\text{rows}, \\text{n}_\\text{column})$\n",
    "    - If $\\mathbf{x}$ has 3 rows and 2 columns, it's shape/dimension is $(3,2)$\n",
    "- Individual scalar elements denoted in uppercase, italics only\n",
    "    - Element in top-right corner of matrix $\\mathbf{x}$ above would be $\\mathbf{x}_\\text{1,2}$\n",
    "- Colon represents an entire row or column:\n",
    "    - Left column of matrix $\\mathbf{x}$ is $\\mathbf{x}_\\text{:,1}$\n",
    "    - Middle row of matrix $\\mathbf{x}$ is $\\mathbf{x}_\\text{2,:}$\n",
    "\n",
    "An example of matrix:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\\\\\n",
    "4 & 5 & 6 \\\\\\\\\n",
    "7 & 8 & 9\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e0adfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3) 9\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_matrix = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "print(x_matrix.shape, x_matrix.size)\n",
    "\n",
    "#basic indexings\n",
    "for _ in range(3):\n",
    "    print(x_matrix[0][_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e7e3cc",
   "metadata": {},
   "source": [
    "## 1.4.1 Matrics in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ab1708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3]) <built-in method size of Tensor object at 0x7feec2c69a30>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_matrix = torch.tensor([[1,2,3], [4,5,6], [7,8,9]])\n",
    "print(x_matrix.shape, x_matrix.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c6ba03",
   "metadata": {},
   "source": [
    "It's just `torch.tensor()` and then inside `()`, it's similar to `np.array()`.\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8073d9c0",
   "metadata": {},
   "source": [
    "## 1.4.2 Generic Tensor Notation\n",
    "- Uppercase, bold, italics, e.g., $\\mathbf{x}$\n",
    "- In a 4-tensor $\\mathbf{x}$, element at position $\\text{(i, j, k, l)}$ denoted as $\\mathbf{x}_\\text{(i, j, k, l)}$\n",
    "\n",
    "As an example, rank 4 tensors are common for images, where each dimension corresponds to:\n",
    "1. Number of images in training batches, e.g., 32\n",
    "2. Image height in pixels, e.g., 28 for **MNIST Digits**\n",
    "3. Image width in pixels, e.g., 28\n",
    "4. Number of color channels, e.g., 3 for full-color images (RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "589415ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]]) torch.Size([32, 28, 28, 3]) <built-in method size of Tensor object at 0x7faf22a11490>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "images = torch.zeros([32,28,28,3])\n",
    "print(images, images.shape, images.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96255cc5",
   "metadata": {},
   "source": [
    "$32$ is for **batches**, $28, 28$ is for **height and width**, $3$ is for **color channels.** This tensor could determine an image after turn into a tensor.\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2643714c",
   "metadata": {},
   "source": [
    "## 2. Tensor Transposition\n",
    "- Transpose of scalars itself, e.g., $x\\top = x$\n",
    "- Transpose of veector, converts column to row and vice versa (other)\n",
    "- Scalar and vector transpostion are special cases of matrix transposition\n",
    "    - Flip of axes over main diagional such that:\n",
    "    $(\\mathbf{x}\\top)_\\text{i, j} = \\mathbf{x}_\\text{j ,i}$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "X_{1,1} & X_{1,2} \\\\\\\\\n",
    "X_{2,1} & X_{2,2} \\\\\\\\\n",
    "X_{3,1} & X_{3,2}\n",
    "\\end{bmatrix}^\\top\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "X_{1,1} & X_{2,1} & X_{3,1} \\\\\\\\\n",
    "X_{1,2} & X_{2,2} & X_{3,2}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dbfacbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4 7]\n",
      " [2 5 8]\n",
      " [3 6 9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_tensor = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "print(x_tensor.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f4ee1",
   "metadata": {},
   "source": [
    "Basically just row $\\to$ column or column $\\to$ row.\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b10438",
   "metadata": {},
   "source": [
    "## 2.1 Basic Tensor Arithmetic\n",
    "- Adding or multiplying with scalar applies operation to all elements and tensor shape is retained. (เก็บ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03907adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n",
      "[[ 2  4  6]\n",
      " [ 8 10 12]\n",
      " [14 16 18]]\n",
      "[[ 4  6  8]\n",
      " [10 12 14]\n",
      " [16 18 20]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_basic = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "print(x_basic+2)\n",
    "print(x_basic*2)\n",
    "print(x_basic*2+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d164aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  6,  8],\n",
      "        [10, 12, 14],\n",
      "        [16, 18, 20]])\n",
      "tensor([[ 4,  6,  8],\n",
      "        [10, 12, 14],\n",
      "        [16, 18, 20]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_basic = torch.tensor([[1,2,3], [4,5,6], [7,8,9]])\n",
    "print(x_basic*2+2)\n",
    "\n",
    "print(torch.add(torch.mul(x_basic, 2), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78a7562",
   "metadata": {},
   "source": [
    "**If 2 tensors have the same size, operations are often by default applied element-wise, This is not matrix multiplication**. But is rather **Hadamard Product** or simply element-wise product. The mathematical notation is $A \\odot X$\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08d00e4",
   "metadata": {},
   "source": [
    "## 2.2 Tensor Reduction\n",
    "- Calculating the sum across all elements of a tensor is a common operation. For example:\n",
    "    - For vector $x$ of length $n$, we calculate sum of a set of value from the first value to the $n^\\text{th}$ value.\n",
    "    - For matrix $X$ with $m \\times n$ dimensions, we calculate:\n",
    "        1. Inner sum, sum across the column for a specific row\n",
    "        2. Outer sum, repeats the process for every row and sum it all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61d8739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45)\n",
      "tensor(45)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_reduction = torch.tensor([[1,2,3], [4,5,6], [7,8,9]])\n",
    "print(x_reduction.sum())\n",
    "\n",
    "print(torch.sum(x_reduction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c73445d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12, 15, 18])\n",
      "tensor([ 6, 15, 24])\n",
      "tensor([12, 15, 18])\n"
     ]
    }
   ],
   "source": [
    "#can also be done along one specific axis alone\n",
    "print(x_reduction.sum(axis=0)) #summing all rows\n",
    "print(x_reduction.sum(axis=1)) #summing all columns\n",
    "\n",
    "print(torch.sum(x_reduction, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.15 (3.10.15)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
